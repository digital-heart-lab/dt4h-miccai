<!--
author hozenli (hozen.site)
emial hozen@live.com
-->
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>digital twin for healthcare</title>
  <link rel="icon" href="./assets/logo-icon-Yuhzs48p.png" />
  <script type="module" crossorigin src="./assets/index-D2yorGKU.js"></script>
  <link rel="stylesheet" crossorigin href="./assets/index-BZRbcNZz.css">
</head>

<body>
  <section class="hero" id="hero">
    <img title="logo" class="hero-logo" src="./assets/logo-icon-Yuhzs48p.png" />
    <div class="hero-title">Digital Twin for Healthcare</div>
    <div class="copyright">
      &copy; International Workshop on Digital Twin for Healthcare (DT4H) in
      <a href="https://conferences.miccai.org/2025/en/default.asp">MICCAI 2025 (Daejeon, Republic of Korea)</a>
    </div>
  </section>
  <main>
    <section class="overview-wrap" id="overview-wrap">
      <div class="section-inner">
        <h1 href="#overview" class="section-title" id="overview">Overview</h1>
        <div class="section-content">
          <p>
            Digital twin (DT) is an emerging frontier in healthcare, offering
            dynamic, patient-specific virtual models that combine medical
            imaging, physiological data, and computational simulations to
            replicate and predict real-world health outcomes. While DT
            technology is still nascent in the MICCAI community, its potential
            to transform personalized medicine, surgical planning, and
            clinical decision-making is immense. This workshop seeks to
            establish DTs as a vibrant new topic within the MICCAI community,
            bridging interdisciplinary domains like medical imaging,
            computational modeling in medicine, biomechanics, and trustworthy
            AI.
          </p>

          <p>
            By introducing this workshop, we aim to catalyze discussions on
            integrating DT models with more conventional medical imaging and
            computational tools, providing a forum to explore innovations and
            build a new MICCAI sub-community dedicated to digital twins in
            healthcare. This workshop is strategically positioned to expand
            MICCAI‚Äôs scope by attracting researchers from fields such as
            computational modeling, electrophysiology, hemodynamic,
            biomechanical modeling, and sensor data analysis. DTs not only
            align with MICCAI topics like image-guided surgery, personalized
            medicine, and trustworthy AI, but also open doors to underexplored
            applications, including real-time patient monitoring and
            population imaging informatics. The workshop also emphasizes
            inclusivity by addressing affordable and accessible imaging
            solutions for DTs, especially in under-represented populations.
          </p>
        </div>
      </div>
    </section>
    <section>
      <div class="section-inner">
        <h1 href="#topic" class="section-title" id="topic">Topic</h1>
        <div class="section-content section-text">
          <ul>
            <li>Digital twin modeling for organs, tissues, and diseases</li>
            <li>
              Multi-modal data integration (imaging, signals, genomics,
              biosensors)
            </li>
            <li>
              AI-driven simulation and predictive modeling for digital twins
            </li>
            <li>
              Digital twin-guided diagnosis, treatment, and intervention
              planning
            </li>
            <li>
              Verification, Validation, and uncertainty quantification in
              digital twins
            </li>
            <li>
              Trustworthy AI, fairness, and explainability in digital twin
              applications
            </li>
            <li>
              Cloud-based and federated learning approaches for scalable
              digital twins
            </li>
            <li>
              Ethical, regulatory, and clinical translation challenges of
              digital twins
            </li>
            <li>
              Digital twins for drug development and in silico clinical trials
            </li>
            <li>
              Simulation and visualization techniques for clinical
              environments
            </li>
          </ul>
        </div>
      </div>
    </section>
    <section>
      <div class="section-inner">
        <h1 href="#timeline" class="section-title" id="timeline">Timeline</h1>
        <div class="timeline">
          <div class="timeline-item">
            <div class="timeline-month">May</div>
            <div class="timeline-events">
              <div class="timeline-event">
                Paper Abstract Submission. 20 May 2025
              </div>
            </div>
          </div>
          <div class="timeline-item">
            <div class="timeline-month">June</div>
            <div class="timeline-events">
              <div class="timeline-event">
                Paper Submission Deadline. <s>15 June</s> 30 June 2025
              </div>
            </div>
          </div>
          <div class="timeline-item">
            <div class="timeline-month">July</div>
            <div class="timeline-events">
              <div class="timeline-event">Reviews Due. 15 July 2025</div>
              <div class="timeline-event">
                Notification of Acceptance. 20 July 2025
              </div>
            </div>
          </div>
          <div class="timeline-item">
            <div class="timeline-month">Aug</div>
            <div class="timeline-events">
              <div class="timeline-event">
                Camera Ready Submission. 1 August 2025
              </div>
            </div>
          </div>
          <div class="timeline-item">
            <div class="timeline-month">Sep</div>
            <div class="timeline-events">
              <div class="timeline-event">
                DT4H workshop (Daejeon, Republic of Korea). 23 September 2025
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section>
      <div class="section-inner">
        <h1 href="#call-for-paper" class="section-title" id="call-for-paper">
          Call for Paper
        </h1>
        <div class="section-content">
          <p>
            We invite original research contributions on digital twins for
            healthcare. Papers should be a maximum of 8 pages (including text,
            figures, and tables) with up to 2 additional pages for references.
            Submissions must follow the Springer LNCS format (<a download
              href="https://conferences.miccai.org/2025/files/downloads/MICCAI2025-LaTeX-Template.zip">Latex</a>
            or
            <a download href="https://conferences.miccai.org/2025/files/downloads/MICCAI2025-Word-Template.zip">MS
              Word</a>
            templates) and undergo double-blind peer review. The workshop will
            be held in person only, and authors of accepted papers are
            required to present their work in person.
          </p>
          <p>
            All submissions will be reviewed by external experts and the
            organizing committee for oral or poster presentation. Accepted
            papers will be published with Springer LNCS, and the best papers
            will be recognized with industry-sponsored awards. We encourage
            both theoretical and applied research, including proof-of-concept
            studies that explore novel directions in digital twins. As MICCAI
            expands its global reach, we especially welcome submissions that
            address challenges in digital twins for low- and middle-income
            countries. This workshop will also feature live demonstrations,
            allowing authors to showcase their digital twin applications in
            AI-driven modeling, real-time simulations, and clinical decision
            support.
          </p>
          <p>
            Submissions should be made via
            <a href="https://cmt3.research.microsoft.com/DT4H2025/">CMT system</a>, with email registration required
            before submission. If you
            experience any issues, please contact the Program Chairs via the
            submission platform or email. We invite contributions on topics
            such as:
          </p>
          <ul>
            <li>Development of digital twins using medical imaging data.</li>
            <li>
              Integrating imaging and non-imaging data for dynamic digital
              twins.
            </li>
            <li>
              Computational modeling of specific diseases (e.g.,
              cardiovascular, neurology, oncology, pulmonology oncology, etc).
            </li>
            <li>AI techniques for digital twin efficiency and accuracy.</li>
            <li>
              Validation and deployment challenges for digital twins in
              clinical practice.
            </li>
          </ul>
        </div>
      </div>
    </section>

    <section>
      <div class="section-inner program">
        <h1 href="#program" class="section-title" id="program">Program</h1>
        <div class="section-content">
          <h2 class="section-title" id="daily-agenda">Agenda</h2>
          <p style="font-size: 1.25rem; text-align: center;">
            üìÖ 23 Sep 2025 üìç <a target="_blank" href="https://maps.app.goo.gl/jRBqKpZFv5cVXpoY8">Daejeon, South
              Korea</a> (DCC1-2F-205)
          </p>
          <div class="agenda">
            <div class="agenda-time" style="grid-row: 1; grid-column: 1;">13:30</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 2; grid-column: 1;">40</div>
            <div class="agenda-event agenda-event--1" style="grid-row: 2/3; grid-column: 2;">Opening Remarks</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 3; grid-column: 1;">50</div>
            <div class="agenda-event agenda-event--1" style="grid-row: 2/3; grid-column: 2;">Opening Remarks</div>
            <div class="agenda-time" style="grid-row: 4; grid-column: 1;">14:00</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 5; grid-column: 1;">10</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 6; grid-column: 1;">20</div>
            <div class="agenda-event agenda-event--2" style="grid-row: 3/7; grid-column: 2;"><a
                href="#keynote-1">Keynote 1: Prof. Linwei Wang</a></div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 7; grid-column: 1;">30</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 8; grid-column: 1;">40</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 9; grid-column: 1;">50</div>
            <div class="agenda-time" style="grid-row: 10; grid-column: 1;">15:00</div>
            <div class="agenda-event agenda-event--3" style="grid-row: 7/11; grid-column: 2;"><a
                href="#oral-session-1">Oral Session 1: Session Chair: Xiaoyue Liu</a></div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 11; grid-column: 1;">10</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 12; grid-column: 1;">20</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 13; grid-column: 1;">30</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 14; grid-column: 1;">40</div>
            <div class="agenda-event agenda-event--4" style="grid-row: 11/15; grid-column: 2;"><a
                href="#keynote-2">Keynote 2: Prof. Mathias Unberath</a></div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 15; grid-column: 1;">50</div>
            <div class="agenda-time" style="grid-row: 16; grid-column: 1;">16:00</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 17; grid-column: 1;">10</div>
            <div class="agenda-event agenda-event--5" style="grid-row: 15/18; grid-column: 2;">Poster Session/Break
            </div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 18; grid-column: 1;">20</div>
            <div class="agenda-event agenda-event--6" style="grid-row: 18/19; grid-column: 2;">Sponsor Session AWS -
              Product Introduction</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 19; grid-column: 1;">30</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 20; grid-column: 1;">40</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 21; grid-column: 1;">50</div>
            <div class="agenda-time" style="grid-row: 22; grid-column: 1;">17:00</div>
            <div class="agenda-event agenda-event--7" style="grid-row: 19/23; grid-column: 2;"><a
                href="#oral-session-2">Oral Session 2: Session Chair: Yilin Lyu</a></div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 23; grid-column: 1;">10</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 24; grid-column: 1;">20</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 25; grid-column: 1;">30</div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 26; grid-column: 1;">40</div>
            <div class="agenda-event agenda-event--8" style="grid-row: 23/27; grid-column: 2;"><a
                href="#keynote-3">Keynote 3: Prof. Henggui Zhang</a></div>
            <div class="agenda-time agenda-time--ticket" style="grid-row: 27; grid-column: 1;">50</div>
            <div class="agenda-event agenda-event--9" style="grid-row: 27/28; grid-column: 2;">Discussion/Awards</div>
            <div class="agenda-time" style="grid-row: 28; grid-column: 1;">18:00</div>
            <div class="agenda-event agenda-event--10" style="grid-row: 28/28; grid-column: 2;">Closing</div>
          </div>
          <h2 class="section-title" id="keynote-speakers">Keynote Speakers</h2>
          <div class="keynote" id="keynote-1">
            <div class="speaker">
              <img class="speaker__avatar" src="./assets/Linwei-Wang-D9b64Ygd.jpg" alt="Mathias Unberath" />
              <div class="speaker__name">
                <a href="https://www.rit.edu/cblwang/" target="_blank">Linwei Wang</a>
              </div>
              <div class="speaker__title">
                Professor, Rochester Institute of Technology
              </div>
            </div>
            <div class="swiper">
              <div class="swiper__body">
                <div class="swiper-item">
                  <div class="swiper-item__title">Predictive Hybrid Digital Twins: Theory, Methods, and Applications
                  </div>
                  <div class="swiper-item__body">
                    <div class="keynote-title">
                    </div>
                    <div class="keynote-content">
                      Advances in digital-twin technology within the healthcare sector are confronted with a
                      long-standing challenge: instead of a one-time static construction that fits observed data, a
                      digital twin needs to rapidly adapt to live data and to provide predictive decision support
                      beyond
                      what has been observed. Attaining these breakthroughs face two fundamental hurdles. First,
                      current
                      mechanistic models struggle with rapid adaptation and imperfect knowledge, while data-driven
                      models are limited in interpretability and generalizability. Second, the prevalent twinning
                      strategies based on data-fitting, previously largely tailored for mechanistic models, become the
                      root cause of an un-identifiable data-driven model with limited predictive capabilities. In this
                      talk, we discuss our recent efforts in addressing these challenges towards the ultimate goal of
                      predictive twinning: a what-how & when meta-learning framework for learning to rapidly and
                      continually personalize a latent forecasting function, endowed with strong predictive ability
                      owing to its theoretical identifiability, and hybrid neural-mechanistic modeling that combines
                      the
                      generalizable and interpretable mechanistic know-how with flexible data-driven learning to
                      resolve
                      the residual between general knowledge and individuals‚Äô data. We will extend these discussions
                      to
                      applications in learning personalized digital twins of the heart.
                    </div>
                  </div>
                </div>
                <div class="swiper-item">
                  <div class="swiper-item__title">BIOGRAPHY</div>
                  <div class="speaker-bio">
                    Dr. Linwei Wang is a Professor of Computing and
                    Information Sciences at the Rochester Institute of
                    Technology (RIT) in Rochester, NY, where she serves as the
                    Director of the Personalized Healthcare Technology
                    (PHT180) Research Center that consists of over 120 faculty
                    affiliates across nine colleges at RIT. Prior to that, Dr.
                    Wang obtained her BS degree in Optic-Electrical
                    Engineering from Zhejiang University (China) in 2005, her
                    M.Phil degree in Electronic and Computer Engineering from
                    Hong Kong University of Science and Technology in 2007,
                    and her PhD in Computing and Information Sciences from RIT
                    prior to joining the faculty of RIT in 2009. Dr. Wang also
                    directs the Computational Biomedical Lab at RIT, with core
                    research interests centered around statistical inference,
                    Bayesian deep learning, and inverse problems with
                    applications to signal and image analysis in a variety of
                    domains including healthcare, astrophysics, and material
                    design. Dr. Wang is a recipient of the NSF CAREER Award in
                    2014 and the United States Presidential Early Career Award
                    for Scientists and Engineers (PECASE) in 2019. Dr. Wang
                    currently serves as the Executive Secretary on the Board
                    of the Medical Image Computing and Computer-Assisted
                    Intervention (MICCAI) Society.
                  </div>
                </div>
              </div>
              <div class="swiper-switch swiper-switch-left">
                <svg class="svg-icon" viewBox="0 0 1024 1024">
                  <path d="M 768 20 L 256 512 L 768 1004" stroke="currentColor" stroke-width="60" fill="none"
                    stroke-linecap="round" stroke-linejoin="round"></path>
                </svg>
              </div>
              <div class="swiper-switch swiper-switch-right">
                <svg class="svg-icon" viewBox="0 0 1024 1024">
                  <path d="M 256 20 L 768 512 L 256 1004" stroke="currentColor" stroke-width="60" fill="none"
                    stroke-linecap="round" stroke-linejoin="round"></path>
                </svg>
              </div>
              <div class="swiper-indictor-wrap">
                <div class="swiper-indictor swiper-indictor">
                  <div class="swiper-indictor__btn"></div>
                </div>
                <div class="swiper-indictor">
                  <div class="swiper-indictor__btn"></div>
                </div>
              </div>
            </div>
          </div>
          <div class="keynote" id="keynote-2">
            <div class="speaker">
              <img class="speaker__avatar" src="./assets/Mathias-Unberath-BZiQdJXq.jpg" alt="Mathias Unberath" />
              <div class="speaker__name">
                <a href="https://mathiasunberath.github.io/" target="_blank">Mathias Unberath</a>
              </div>
              <div class="speaker__title">
                Associate Professor, Johns Hopkins University
              </div>
            </div>
            <div class="swiper">
              <div class="swiper__body">
                <div class="swiper-item">
                  <div class="swiper-item__title">
                    Digital Twins for Surgical Data Science
                  </div>
                  <div class="swiper-item__body">
                    <div class="keynote-content">
                      Digital twins are virtual representations of real-world
                      environments and processes. By virtue of being
                      computational, digital twins offer abundant
                      possibilities for optimizing and supporting real-world
                      processes through algorithmic analysis and feedback. In
                      this context, digital twins play a critical role in
                      advancing surgical data science, an emerging research
                      thrust striving to improve the quality of interventional
                      healthcare. In this talk, I will first provide a
                      contextual framework in support of digital twins as a
                      useful representation for scene analysis and then
                      showcase some exciting research outcomes and
                      opportunities that demonstrate the potential for digital
                      twins in surgical data science and beyond.
                    </div>
                  </div>
                </div>
                <div class="swiper-item">
                  <div class="swiper-item__title">BIOGRAPHY</div>
                  <div class="speaker-bio">
                    Dr. Mathias Unberath is the John C. Malone Associate
                    Professor of Computer Science at Johns Hopkins University.
                    He‚Äôs the Research Director for Embodied AI in the Data
                    Science and AI Institute, core member of the Malone Center
                    for Engineering in Healthcare and the Laboratory for
                    Computational Sensing and Robotics, and a member of the
                    Institute for Assured Autonomy. He holds secondary
                    appointments in the School of Medicine. With his team, the
                    ARCADE research group on Advanced Robotics and
                    Computationally AugmenteD Environments, he builds the
                    future of AI-assisted medicine. Through synergistic
                    research on imaging, computer vision, machine learning,
                    and interaction design, he creates human-centered
                    solutions that are embodied in emerging technology such as
                    mixed reality and robotics. Mathias has published more
                    than 190 journal and conference articles, and has received
                    numerous awards, grants, and fellowships, including the
                    NSF Career, NIH NIBIB R21 Trailblazer and Google Research
                    Scholar Award, and more than 20 international paper
                    awards.
                  </div>
                </div>
              </div>
              <div class="swiper-switch swiper-switch-left">
                <svg class="svg-icon" viewBox="0 0 1024 1024">
                  <path d="M 768 20 L 256 512 L 768 1004" stroke="currentColor" stroke-width="60" fill="none"
                    stroke-linecap="round" stroke-linejoin="round"></path>
                </svg>
              </div>
              <div class="swiper-switch swiper-switch-right">
                <svg class="svg-icon" viewBox="0 0 1024 1024">
                  <path d="M 256 20 L 768 512 L 256 1004" stroke="currentColor" stroke-width="60" fill="none"
                    stroke-linecap="round" stroke-linejoin="round"></path>
                </svg>
              </div>
              <div class="swiper-indictor-wrap">
                <div class="swiper-indictor swiper-indictor">
                  <div class="swiper-indictor__btn"></div>
                </div>
                <div class="swiper-indictor">
                  <div class="swiper-indictor__btn"></div>
                </div>
              </div>
            </div>
          </div>
          <div class="keynote" id="keynote-3" style="margin-bottom: 80px;">
            <div class="speaker">
              <img class="speaker__avatar" src="./assets/Henggui-Zhang-Der1_32t.jpg" alt="Henggui Zhang" />
              <div class="speaker__name">
                <a href="https://scholar.google.com/citations?user=m2Q6lyoAAAAJ&hl=en">Henggui Zhang</a>
              </div>
              <div class="speaker__title">
                Chief Scientist, Beijing Academy of Artificial Intelligence. Chair Professor, University of Manchester
              </div>
            </div>
            <div class="swiper">
              <div class="swiper__body">
                <div class="swiper-item">
                  <div class="swiper-item__title">
                    Development of the virtual heart for the study of cardiac arrhythmias
                  </div>
                  <div class="swiper-item__body">
                    <div class="keynote-content">
                      Cardiac arrhthmias are the most common cardiac diseases causing morbidity and mortality.
                      Understanding and treating cardiac arrhythmias remains a significant challenge in cardiovascular
                      practices. While experimental techniques provide valuable insights, they are often limited in
                      resolution, scalability, and personalisation. In this talk, I will present the development and
                      application of a multi-scale, multi-physics virtual heart platform - an integrative
                      computational
                      framework that simulates cardiac electrophysiology from ion channels to the whole heart. Built
                      upon biophysically detailed cellular models, tissue-level conduction networks, and anatomically
                      accurate geometries, the virtual heart enables mechanistic exploration of arrhythmia initiation,
                      maintenance, and termination in normal and abnormal physiological/pathological conditions.
                    </div>
                  </div>
                </div>
                <div class="swiper-item">
                  <div class="swiper-item__title">BIOGRAPHY</div>
                  <div class="speaker-bio">
                    Dr. Henggui Zhang is Chief Scientist at the Beijing Academy of Artificial Intelligence, where he
                    leads the Centre for Life Simulation and Modelling, and Chair Professor of Biological Physics at
                    the
                    University of Manchester.
                    ¬†
                    Dr. Zhang received a BSc in Physics (1985), an MSc in Laser Physics and Computer Science (1988),
                    and
                    a PhD in Nonlinear Science focusing on Mathematical Cardiology (1990) from the University of
                    Leeds.
                    He subsequently held postdoctoral fellowships at both Johns Hopkins University and the University
                    of
                    Leeds. In 2001, he joined UMIST (now part of the University of Manchester), where he progressed
                    from
                    Lecturer to Reader and ultimately the Chair of Biological Physics. He was elected as a Fellow of
                    the
                    Royal Society of Biology (FRSB) and Fellow of the Royal Society of Arts (FRSA) in 2019.
                    ¬†
                    Dr. Zhang‚Äôs research spans multi-scale modeling of cardiac cells, tissues, and organs;
                    spatiotemporal complexity; and nonlinear and chaotic time-series dynamics. He has published over
                    500
                    scientific works, including more than 280 peer-reviewed articles in computational cardiology,
                    electrophysiology, and systems biology. His Google Scholar profile reports an h-index of 60 with
                    over 14,000 citations, reflecting his significant contributions to atrial fibrillation research,
                    sinoatrial node modeling, digital twin heart simulations, AI-driven arrhythmia detection, and drug
                    safety evaluation through in-silico pharmacological modeling. As a pioneer in computational
                    cardiology and digital physiological modeling, Dr. Zhang continues to shape the field through
                    innovations that bridge foundational science and real-world clinical applications.
                  </div>
                </div>
              </div>
              <div class="swiper-switch swiper-switch-left">
                <svg class="svg-icon" viewBox="0 0 1024 1024">
                  <path d="M 768 20 L 256 512 L 768 1004" stroke="currentColor" stroke-width="60" fill="none"
                    stroke-linecap="round" stroke-linejoin="round"></path>
                </svg>
              </div>
              <div class="swiper-switch swiper-switch-right">
                <svg class="svg-icon" viewBox="0 0 1024 1024">
                  <path d="M 256 20 L 768 512 L 256 1004" stroke="currentColor" stroke-width="60" fill="none"
                    stroke-linecap="round" stroke-linejoin="round"></path>
                </svg>
              </div>
              <div class="swiper-indictor-wrap">
                <div class="swiper-indictor swiper-indictor">
                  <div class="swiper-indictor__btn"></div>
                </div>
                <div class="swiper-indictor">
                  <div class="swiper-indictor__btn"></div>
                </div>
              </div>
            </div>
          </div>
          <h2 class="section-title" id="oral-presentations">Oral Presentations</h2>
          <div class="oral-session" id="oral-session-1">
            <div class="oral-sesseion__title">Oral Session 1</div>
            <ol class="oral-session__list">
              <li>
                Trung-Dung Hoang (UniBE, Switzerland)
                <br>
                Real-Time Digital Twin for Type 1 Diabetes using Simulation-Based inference
              </li>
              <li>
                Minjee Seo (Yonsei University, South Korea)
                <br>
                Acoustic Simulation with Deep Learning for Low-intensityTranscranial Focused Ultrasound Digital Twins
              </li>
              <li>
                Yilin Lyu (NUS, Singapore)
                <br>
                Personalized 3D Ml Geometry Reconstruction from Cine MRl with Explicit Cardiac Motion Modeling
              </li>
              <li>
                Seonaeng Cho (Yonsei University, South Korea)
                <br>
                Towards Digital Twin of RF Ablation: Real-Time Prediction of Time-Dependent Thermal Effects Using
                Transformer
              </li>
            </ol>
          </div>
          <div class="oral-session" id="oral-session-2">
            <div class="oral-sesseion__title">Oral Session 2</div>
            <ol class="oral-session__list">
              <li>
                Xiaoyue Liu (NUS, Singapore)
                <br>
                Personalized 4D Whole Heart Geometry Reconstruction from Cine MRl for Cardiac Digital Twins
              </li>
              <li>
                Robert Graf (TUM, Germany)
                <br>
                Rules based Key-Point Extraction for MR-Guided Biomechanical Digital Twins of
                the Spine
              </li>
              <li>
                Mathias Unberath (JHU, USA)
                <br>
                Towards Robust Algorithms for Surgical Phase Recognition via Digital Twin Representation
              </li>
              <li>
                Oliver Frings (Siemens Healthineers, Germany)
                <br>
                Retrospective Evaluation of a Patient-Specific Liver Digital Twin to Predict Thermal Ablation Outcomes
                in
                HCC
              </li>
            </ol>
          </div>
        </div>
      </div>
    </section>

    <section>
      <div class="section-inner accepted-papers">
        <h1 href="#accepted-papers" class="section-title" id="accepted-papers">Accepted Papers</h1>
        <div class="section-content">
          <div class="paper">
            <div class="paper-title">
              Personalized 3D Myocardial Infarct Geometry Reconstruction from Cine MRI with Explicit Cardiac Motion
              Modeling
            </div>
            <div class="paper-authors">
              Authors: Yilin Lyu, Fan Yang, Xiaoyue Liu, Zichen Jiang, Joshua R. Dillon, Debbie
              Zhao, Martyn P.
              Nash, Charlene Mauger, Alistair Young, Ching-Hui Sia, Mark YY Chan, Lei Li*
            </div>
          </div>
          <div class="paper">
            <div class="paper-title">
              Microvascular Retinal Digital Twins from Non-Invasive Clinical Images
            </div>
            <div class="paper-authors">
              Authors: Remi Hernandez*, Wahbi El-Bouri
            </div>
          </div>
          <div class="paper">
            <div class="paper-title">
              Validating Digital Twins with Tactile-Visual Liver Phantoms for Robot-Assisted Surgical Workflows
            </div>
            <div class="paper-authors">
              Authors: Chengzheng Mao*, Ying Zhen Tan, Yujia Gao
            </div>
          </div>
          <div class="paper">
            <div class="paper-title">
              A Real-Time Digital Twin for Type 1 Diabetes using Simulation-Based Inference
            </div>
            <div class="paper-authors">
              Authors: Trung-Dung Hoang*, Alceu Emanuel Bissoto, Vihangkumar Naik, Tim Fluehmann, Artemii Shlychkov,
              Jos√© Fernando Garcia Tirado, Lisa Margret Koch
            </div>
          </div>
          <div class="paper">
            <div class="paper-title">
              Retrospective Evaluation of a Patient-Specific Liver Digital Twin to Predict Thermal Ablation Outcomes in
              HCC
            </div>
            <div class="paper-authors">
              Authors: Chlo√© Audigier*, Felix Meister, Fouad Georges Akkari, Andrea Tonglet, Oliver Frings, Rafael Duran
            </div>
          </div>
          <div class="paper">
            <div class="paper-title">
              Acoustic Simulation with Deep Learning for Low-intensity Transcranial Focused Ultrasound Digital Twins
            </div>
            <div class="paper-authors">
              Authors: Minjee Seo*, Minwoo Shin, Gunwoo Noh, Seung-Schik Yoo, Kyungho Yoon
            </div>
          </div>
          <div class="paper">
            <div class="paper-title">
              Towards Digital Twin of RF Ablation: Real-Time Prediction of Time-Dependent Thermal Effects Using
              Transformer
            </div>
            <div class="paper-authors">
              Authors: Seonaeng Cho*, Minjee Seo, Minwoo Shin, Kyungho Yoon
            </div>
          </div>
          <div class="paper">
            <div class="paper-title">
              Finite-Element Electrophysiological Modeling of Human Uterine Smooth Muscle Using a Reduced Tong Model
            </div>
            <div class="paper-authors">
              Authors: Zhen Li*, Alberto Corrias
            </div>
          </div>
          <div class="paper">
            <div class="paper-title">
              TF-TransUNet1D: Time-Frequency Guided Transformer U-Net for Robust ECG Denoising in Digital Twin
            </div>
            <div class="paper-authors">
              Authors: Shijie Wang*, Lei Li
            </div>
          </div>
          <div class="paper">
            <div class="paper-title">
              DeformMLP: Effective Deformation Prediction for Breast Cancer Using Graph Topology-Assisted MLPs
            </div>
            <div class="paper-authors">
              Authors: Yong-Min Shin, Kyunghyun Lee, Sunghwan Lim, Kyungho Yoon, Won-Yong Shin*
            </div>
          </div>
          <div class="paper">
            <div class="paper-title">
              Rule-based Key-Point Extraction for MR-Guided Biomechanical Digital Twins of the Spine
            </div>
            <div class="paper-authors">
              Authors: Robert Graf*, Tanja Lerchl, Kati Nispel, Hendrik M√∂ller, Matan Atad, Julian Mc Ginnis, Julius
              Maria Watrinet, Johannes Paetzold, Daniel Rueckert, Jan S. Kirschke
            </div>
          </div>
          <div class="paper">
            <div class="paper-title">
              Towards Robust Algorithms for Surgical Phase Recognition via Digital Twin Representation
            </div>
            <div class="paper-authors">
              Authors: Hao Ding*, Yuqian Zhang, Wenzheng Cheng, Xinyu Wang, Xu Lian, Chenhao Yu, Hongchao Shu, Ji Woong
              Kim, Axel Krieger, Mathias Unberath
            </div>
          </div>
          <div class="paper">
            <div class="paper-title">
              Personalized 4D Whole Heart Geometry Reconstruction from Cine MRI for Cardiac Digital Twins
            </div>
            <div class="paper-authors">
              Authors: Xiaoyue Liu*, Xicheng Sheng, Xiahai Zhuang, Vicente Grau, Mark Y Chan, Ching-Hui Sia, Lei Li
            </div>
          </div>
          <div class="paper">
            <div class="paper-title">
              Secure Medical Digital Twins: A Use-Case Driven Approach
            </div>
            <div class="paper-authors">
              Authors: Salmah Ahmad*, Stefan Wesarg
            </div>
          </div>
          <div class="paper">
            <div class="paper-title">
              Explainable Prediction of Recurrence After Prostate Cancer Radiotherapy Using In Silico Digital Twin Model
              and Machine Learning
            </div>
            <div class="paper-authors">
              Authors: Valentin Septiers*, Carlos Sosa-Marrero, Eleonora Poeta, Hilda Chourak, Aur√©lien Briens, Renaud
              De Crevoisier, Maria Zuluaga, Oscar Acosta
            </div>
          </div>
        </div>
      </div>
    </section>


    <section>
      <div class="section-inner highlights">
        <h1 href="#highlights" class="section-title" id="recap">Recap</h1>
        <div class="section-content">
          <p>
            As part of MICCAI 2025, the Digital Twin for Healthcare (DT4H) workshop was successfully held on September
            23, 2025, in Daejeon, South Korea, gathered a vibrant community of more than 70 participants from 17
            countries. Attendees represented academia, industry, and healthcare institutions, including PhD students,
            postdoctoral researchers, professors, and experts from leading companies and hospitals. The workshop
            stimulated deep discussions on computational modeling, data integration, and clinical applications in
            digital twin for healthcare, and encouraged constructive interdisciplinary interactions among participants.
          </p>
          <figure class="chart-wrap">
            <div id="chartWrapPosition" class="full-width-chart" style="height: 400px;"></div>
            <figcaption>
              Distribution of Participant Roles
            </figcaption>
          </figure>
          <figure class="chart-wrap">
            <div id="chartWrapWorld" class="full-width-chart" style="height: 400px;"></div>
            <figcaption>
              Global Geographic Distribution of Workshop Participants
            </figcaption>
          </figure>
          <h2 class="section-title" id="paper-recap" style="margin-top: 80px">Paper Recap</h2>
          <p>
            DT4H workshop received 23 paper submissions related to digital twin (DT), of which 15 were accepted. The
            workshop proceeding has been published in <a href="https://link.springer.com/book/10.1007/978-3-032-07694-6"
              target="__blank">Spring Nature</a>. The studies spanned
            multiple organs, including the
            brain, eye, heart, pancreas, liver, spine, and uterus, and employed diverse methods such as organ geometry
            reconstruction, biomechanical modeling, disease diagnosis, and surgical monitoring and guidance. Many of the
            works also addressed safety, privacy, and ethical considerations. In these studies, cardiac research
            emphasized personalized lesion modeling and dynamic heart function simulation. Liver highlighted the
            potential of DTs for surgical planning, robot-assisted procedures, and clinical workflow optimization.
            Ophthalmic studies mainly leveraged non-invasive imaging to support precision diagnostics and disease
            prediction. Studies in metabolism and chronic disease management explored DTs for personalized therapy and
            patient management. By integrating a variety of modeling and learning approaches, these studies collectively
            showcase the broad applicability of digital twins in healthcare and their potential for cross- disciplinary
            integration.
          </p>
          <figure class="highlight-figure" style="max-width: 400px;">
            <img src="./assets/proceeding-cover-C8i9ITqi.webp" />
            <figcaption>DT4H 2025
              proceeding <a href="https://link.springer.com/book/10.1007/978-3-032-07694-6" target="__blank">(view
                here)</a>
            </figcaption>
          </figure>
          <h2 class="section-title" id="program-recap" style="margin-top: 80px">Program Recap</h2>
          <p>
            DT4H workshop began with an opening presentation and continued with keynote talks, oral presentations,
            poster sessions, and sponsor events. These diverse sessions showcased the interdisciplinary nature and
            methodological richness of digital twin research, highlighting how medical imaging, computational modeling,
            and biomechanics are closely integrated with data-driven AI. At the closing, the Best Paper, Runner-Up, Best
            Poster, and Best Reviewer awards were announced, recognizing both research excellence in methodology and
            clinical applications, as well as outstanding contributions to academic exchange and peer review.
          <div class="photo-gallery">
            <figure class="highlight-figure">
              <img src="./assets/1-CjqBJWFB.jpg" />
              <figcaption>
              </figcaption>
            </figure>
            <figure class="highlight-figure">
              <img src="./assets/2-CY27-4OS.jpg" />
              <figcaption>
              </figcaption>
            </figure>
            <figure class="highlight-figure">
              <img src="./assets/3-BnZmwafA.jpg" />
              <figcaption>
              </figcaption>
            </figure>
            <figure class="highlight-figure">
              <img src="./assets/4-CbIXOkQ8.jpg" />
              <figcaption>
              </figcaption>
            </figure>
            <figure class="highlight-figure" style="grid-column: 1/-1">
              <img src="./assets/poster-UJxJKXdp.jpg" />
              <figcaption>
              </figcaption>
            </figure>
            <figure class="highlight-figure">
              <img src="./assets/5-BWfefwrU.jpg" />
              <figcaption>
              </figcaption>
            </figure>
            <figure class="highlight-figure">
              <img src="./assets/6-ei1ddhkh.jpg" />
              <figcaption>
              </figcaption>
            </figure>
            <figure class="highlight-figure">
              <img src="./assets/7-C6AllZOk.jpg" />
              <figcaption>
              </figcaption>
            </figure>
            <figure class="highlight-figure">
              <img src="./assets/8-Bnp6bjlu.jpg" />
              <figcaption>
              </figcaption>
            </figure>
            <figure class="highlight-figure">
              <img src="./assets/9-sg2O5pc8.jpg" />
              <figcaption>
              </figcaption>
            </figure>
            <figure class="highlight-figure">
              <img src="./assets/10-CXbKboEH.jpg" />
              <figcaption>
              </figcaption>
            </figure>
          </div>
          <h2 class="section-title" id="acknowledgments" style="margin-top: 80px">Acknowledgments</h2>
          <p>
            Through broad international participation and diverse research topics, DT4H workshop effectively
            demonstrated the feasibility and innovative potential of DT in healthcare. Participants widely anticipate
            future collaborations and exchanges, aiming to further advance the impact and application of DTs. We extend
            our sincere thanks to all participants and supporters, and in particular to our 3 keynote speakers: Prof.
            Linwei Wang, Prof. Mathias Unberath, and Prof. Henggui Zhang, whose presentations provided cutting-edge
            perspectives and deep insights into DT research. We would like to extend our special thanks to our sponsors,
            Amazon AWS, BAAI, SIG-Cardiac, and Digital Heart Lab. Their generous support provided essential resources
            and technical platforms, playing a crucial role in making DT4H workshop a success.
          </p>
        </div>

      </div>
    </section>

    <section>
      <div class="section-inner organizer">
        <h1 href="#organization" class="section-title" id="organization">
          Organization
        </h1>
        <div class="section-content">
          <h2 href="#organizers" class="section-title" id="organizers">
            Organizers
          </h2>
          <div class="person-list">
            <a class="person" href="https://lileitech.github.io/" target="_blank">
              <img class="person-avatar" title="Lei Li" src="./assets/Lei-Li-CSqoIZFO.jpg" />
              <div class="person__body">
                <div class="person-name">Lei Li</div>
                <div class="person-info">
                  Assistant Professor<br />
                  National of University Singapore, Singapore
                </div>
              </div>
            </a>
            <a class="person" href="https://ins-amu.fr/jirsaviktor" target="_blank">
              <img class="person-avatar" title="Viktor Jirsa" src="./assets/Round-Jirsa-V-PMLr8EeJ.jpg" />
              <div class="person__body">
                <div class="person-name">Viktor Jirsa</div>
                <div class="person-info">
                  Professor<br />
                  Institut de Neurosciences des Syst√®mes, France
                </div>
              </div>
            </a>
            <a class="person" href=" https://istbi.fudan.edu.cn/lnen/info/1157/1629.htm" target="_blank">
              <img class="person-avatar" title="Jianfeng Feng" src="./assets/Jianfeng-Feng-BqYi7Q63.jpg" />
              <div class="person__body">
                <div class="person-name">Jianfeng Feng</div>
                <div class="person-info">
                  Professor<br />
                  Fudan University, Shanghai, China
                </div>
              </div>
            </a>
            <a class="person" href=" https://medicine.yale.edu/profile/jun-deng/" target="_blank">
              <img class="person-avatar" title="Jun Deng" src="./assets/Jun-Deng-CgoiziRj.jpg" />
              <div class="person__body">
                <div class="person-name">Jun Deng</div>
                <div class="person-info">
                  Professor<br />
                  Yale University, New Haven, USA
                </div>
              </div>
            </a>
            <a class="person"
              href=" https://mox.polimi.it/people/people-details/?id_staff=551&nome_staff=Luca%20Dede%27"
              target="_blank">
              <img class="person-avatar" title="Luca Dede" src="./assets/Luca-Dede-DE1iFItG.jpg" />
              <div class="person__body">
                <div class="person-name">Luca Dede‚Äô</div>
                <div class="person-info">
                  Associate Professor<br />
                  Politecnico di Milano, Milano, Italy
                </div>
              </div>
            </a>
            <a class="person">
              <img class="person-avatar" title="Sora An" src="./assets/Sora-An-Cv1bQYNS.jpg" />
              <div class="person__body">
                <div class="person-name">Sora An</div>
                <div class="person-info">
                  Research Professor<br />
                  Ewha Womans University, Republic of Korea
                </div>
              </div>
            </a>
          </div>

          <h2 href="#delivery" class="section-title" id="delivery">
            Delivery
          </h2>
          <div class="section-text" style="text-align: center">
            <p>Yilin Lyu, National University of Singapore, Singapore</p>
            <p>Xiaoyue Liu, National University of Singapore, Singapore</p>
          </div>
        </div>
      </div>
    </section>
  </main>
  <aside id="toc">
    <div class="toc__body"></div>
  </aside>
  <footer>
    <div class="footer-inner">
      <div class="footer-item">
        <div class="footer-item-title">Sponsors
          <a href="mailto://lei.li@nus.edu.sg" class="text--muted">üìÆ contact us</a>
        </div>
        <div class="sponsors">
          <a href="https://aws.amazon.com/" class="sponsor">
            <div class="sponsor-logo">
              <img src="./assets/aws-CdVJQUQc.png" />
            </div>
            <div class="sponsor-name">Amazon Web Services</div>
          </a>
          <a href="https://www.baai.ac.cn/" class="sponsor">
            <div class="sponsor-logo">
              <img src="./assets/baai-CUaK7cUf.png" />
            </div>
            <div class="sponsor-name">Beijing Academy of Artificial Intelligence</div>
          </a>
          <a href="https://miccai.org/index.php/special-interest-groups/sig-cardiac/" class="sponsor">
            <div class="sponsor-logo">
              <img src="./assets/SIG-Cardiac-_8-1J8Li.png" />
            </div>
            <div class="sponsor-name">SIG-Cardiac</div>
          </a>
          <a href="https://www.digitalheartlab.com/" class="sponsor">
            <div class="sponsor-logo">
              <img height="40px" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20class='dhlab-logo'%20viewBox='0%200%20763.5%20220.5'%20height='20px'%3e%3cpath%20fill-rule='evenodd'%20stroke='none'%20stroke-linecap='butt'%20stroke-linejoin='miter'%20fill='%23fff'%20d='M744.821,211.000%20C733.690,221.926%20720.012,227.389%20703.790,227.389%20C695.642,227.389%20687.694,225.604%20679.946,222.036%20C672.198,218.468%20665.815,213.660%20660.795,207.613%20C652.065,197.125%20647.700,183.541%20647.700,166.860%20L647.975,102.228%20L688.203,102.228%20L688.513,165.330%20C688.513,179.826%20693.713,187.073%20704.117,187.073%20C708.554,187.073%20712.319,185.562%20715.412,182.539%20C718.503,179.517%20720.050,175.857%20720.050,171.558%20C720.050,167.116%20718.594,163.382%20715.685,160.359%20C712.774,157.337%20709.209,155.825%20704.990,155.825%20C702.007,155.825%20698.588,157.136%20694.733,159.758%20L694.733,114.743%20C699.534,114.306%20703.171,114.088%20705.645,114.088%20C720.994,114.088%20734.144,119.624%20745.094,130.695%20C756.042,141.768%20761.517,155.097%20761.517,170.684%20C761.517,186.636%20755.952,200.075%20744.821,211.000%20ZM585.498,174.726%20C585.498,168.973%20584.097,164.384%20581.297,160.960%20C578.496,157.537%20574.731,155.825%20570.003,155.825%20C565.709,155.825%20561.999,157.392%20558.872,160.523%20C555.743,163.655%20554.180,167.370%20554.180,171.667%20C554.180,176.184%20555.598,179.899%20558.435,182.812%20C561.273,185.726%20564.874,187.182%20569.239,187.182%20C572.802,187.182%20576.114,186.236%20579.169,184.341%20L579.169,226.625%20C575.822,227.207%20572.767,227.499%20570.003,227.499%20C553.634,227.499%20539.993,222.109%20529.081,211.328%20C518.168,200.549%20512.712,187.037%20512.712,170.793%20C512.712,154.988%20518.223,141.585%20529.244,130.586%20C540.266,119.588%20553.670,114.088%20569.457,114.088%20C587.062,114.088%20600.940,119.242%20611.088,129.548%20C621.237,139.856%20626.311,153.931%20626.311,171.776%20L626.311,225.204%20L585.498,225.204%20L585.498,174.726%20ZM457.276,211.055%20C448.255,201.623%20443.745,188.531%20443.745,171.776%20L443.745,76.066%20L488.050,76.066%20L488.050,164.675%20C488.050,171.596%20489.158,176.201%20491.378,178.496%20C493.596,180.790%20497.980,181.938%20504.528,181.938%20L506.819,181.938%20L506.819,225.204%20L495.034,225.204%20C478.883,225.204%20466.296,220.489%20457.276,211.055%20ZM343.131,1.496%20L409.589,1.496%20L409.589,225.204%20L343.131,225.204%20L343.131,1.496%20ZM313.340,225.204%20L246.883,225.204%20L246.883,1.496%20L313.340,1.496%20L313.340,81.474%20L331.837,81.474%20L331.837,140.474%20L313.340,140.474%20L313.340,225.204%20ZM98.582,226.515%20C94.543,226.515%2087.942,226.295%2078.776,225.860%20C78.776,225.860%2078.785,202.575%2078.779,173.578%20C92.584,181.161%20109.773,187.438%20124.326,183.619%20C142.276,175.689%20143.655,168.762%20145.912,127.837%20C146.505,113.099%20136.652,88.555%20130.744,81.692%20C139.881,78.295%20137.710,78.871%20145.037,76.727%20C145.276,70.142%20143.545,67.087%20142.120,64.169%20C134.685,63.029%20131.408,64.829%20121.701,65.337%20C111.235,57.435%20107.138,45.563%20120.826,39.928%20C123.182,33.747%20115.322,28.795%20111.492,28.246%20C100.403,31.853%2084.048,53.032%2080.280,53.363%20C70.793,48.259%2082.830,39.962%2070.946,36.423%20C66.301,37.612%2070.792,36.311%2063.362,37.884%20C63.721,61.220%2038.900,96.739%2037.401,110.313%20C33.401,129.715%2046.428,150.174%2057.236,159.086%20C59.774,161.179%2063.483,163.997%2067.972,166.998%20C67.972,198.528%2067.972,225.204%2067.972,225.204%20L1.515,225.204%20L1.515,1.496%20L88.106,1.496%20C126.082,1.496%20155.816,10.129%20177.316,27.391%20C202.851,48.041%20215.619,76.066%20215.619,111.466%20C215.619,145.337%20204.705,172.980%20182.881,194.393%20C161.054,215.809%20132.956,226.515%2098.582,226.515%20Z'%3e%3c/path%3e%3c/svg%3e" />
            </div>
            <div class="sponsor-name">Digital Heart Lab</div>
          </a>
        </div>
      </div>
    </div>
  </footer>
  <div class="foot-copyright">
    Copyright &copy; 2025 Digital Twin for Healthcare. All rights reserved.
  </div>

  <div id="notification-banner">üéâ DT4H 2025 Successfully Concluded on September 23, 2025! üëâ View <a
      href="#recap">Recap</a>
  </div>

  <script>
    const overviewEl = document.querySelector("#overview-wrap");
    const tocElement = document.querySelector("div.toc__body");
    const tocWrapElement = document.querySelector("aside#toc");
    const heroElement = document.querySelector("#hero");

    const sectionScrollAction = {
      UP_IN: 0,
      DOWN_OUT: 1,
    };

    let asideVisible = false;

    window.addEventListener("scroll", onScroll);

    const headers = getHeaders();
    const headerToToc = new Map();

    const toc = generateToc(headers, headerToToc);
    const tocElements = generateTocElements(toc);
    renderToc(tocElement, tocElements);

    listenSectionScrollAction(headers, {
      onUpIn: onSectionUpIn,
      onDownOut: onSectionDownOut,
    });

    function getHeaders() {
      return Array.from(document.querySelectorAll("h1, h2, h3"));
    }

    function generateToc(headers, headerToToc) {
      const toc = [];
      let wrap = {
        level: 0,
        children: toc,
        parent: null,
      };

      let previous = null;

      for (const header of headers) {
        const { tagName, innerText, id } = header;
        const level = Number(tagName.slice(-1));

        const tocItem = {
          level,
          tag: tagName,
          id,
          text: innerText,
          parent: null,
        };

        tocItem.previous = previous;
        previous = tocItem;

        headerToToc.set(header, tocItem);

        if (level <= wrap.level) {
          while (wrap && wrap.level >= level) {
            wrap = wrap.parent;
          }
        }

        wrap.children ||= [];
        wrap.children.push(tocItem);
        tocItem.parent = wrap;

        wrap = tocItem;
      }

      return toc;
    }

    function generateTocElements(toc) {
      const tocBodyClassName = "toc-item__body";

      const createTocItemElement = (toc) => {
        const wrapElement = document.createElement("DIV");
        wrapElement.className = `toc-item toc-item--${toc.level}`;
        const titleElement = document.createElement("A");
        titleElement.innerText = toc.text;
        titleElement.className = "toc-item-title";
        titleElement.href = `#${toc.id}`;
        const bodyElement = document.createElement("DIV");
        bodyElement.className = tocBodyClassName;

        wrapElement.append(titleElement, bodyElement);

        return wrapElement;
      };

      toc.forEach((item) => (item.element = createTocItemElement(item)));
      const tocElements = toc.map((item) => item.element);

      const stack = toc.map((item, i) => [item, tocElements[i]]);

      while (stack.length) {
        const [tocItem, tocElement] = stack.pop();

        if (!tocItem.children) {
          continue;
        }

        const tocElementBody = tocElement.querySelector(
          `div.${tocBodyClassName}`
        );

        for (const child of tocItem.children) {
          const childElement = createTocItemElement(child);
          tocElementBody.appendChild(childElement);
          child.element = childElement;
          stack.push([child, childElement]);
        }
      }

      return tocElements;
    }

    function renderToc(wrap, elements) {
      wrap.append(...elements);
    }

    const tocActiveClass = "toc--active";
    function onSectionUpIn(e) {
      headerToToc
        .values()
        .forEach((toc) => toc.element.classList.remove(tocActiveClass));
      headerToToc.get(e.target).element.classList.add(tocActiveClass);
    }

    function onSectionDownOut(e) {
      headerToToc
        .values()
        .forEach((toc) => toc.element.classList.remove(tocActiveClass));
      headerToToc
        .get(e.target)
        .previous?.element.classList.add(tocActiveClass);
    }

    function onScroll(e) {
      const { height } = overviewEl.getBoundingClientRect();
      const { scrollTop } = document.documentElement;

      const percent = Math.min(1, scrollTop / (0.8 * (height - 160)));

      setOverviewWidth(percent, 1);
      setHeroFilterVisible(percent);

      toggleToc(percent === 1);
    }

    function toggleToc(visible) {
      if (visible === asideVisible) {
        return;
      }
      asideVisible = visible;
      if (visible) {
        tocWrapElement.style.animationName = "slide-in";
      } else {
        tocWrapElement.style.animationName = "slide-out";
      }
    }

    function setOverviewWidth(p) {
      document.body.style.setProperty("--scroll-percent", p);
    }

    function setHeroFilterVisible(p) {
      if (p > 0.2) {
        heroElement.style.setProperty("--filter-visible", "block");
      } else {
        heroElement.style.setProperty("--filter-visible", "none");
      }
    }

    function listenSectionScrollAction(sections, { onUpIn, onDownOut }) {
      const scrollToTopObserver = new IntersectionObserver(
        (entries) => {
          entries.forEach((entry) => {
            const action = getSectionEntryAction(entry);
            if (action === sectionScrollAction.UP_IN) {
              onUpIn(entry);
            } else if (action === sectionScrollAction.DOWN_OUT) {
              onDownOut(entry);
            }
          });
        },
        {
          rootMargin: "-65px 0px -100% 0px",
          threshold: 0,
        }
      );

      sections.forEach((section) => {
        scrollToTopObserver.observe(section);
      });
    }

    function getSectionEntryAction(entry) {
      const { top } = entry.boundingClientRect;
      if (top < 60) {
        return null;
      }
      if (entry.isIntersecting) {
        return sectionScrollAction.UP_IN;
      } else {
        return sectionScrollAction.DOWN_OUT;
      }
    }

    const swipers = document.querySelectorAll(".swiper");
    swipers.forEach((swiper) => {
      const swiperBody = swiper.querySelector(".swiper__body");
      const swiperItems = swiperBody.querySelectorAll(".swiper-item");
      const swiperSwitchLeft = swiper.querySelector(".swiper-switch-left");
      const swiperSwitchRight = swiper.querySelector(".swiper-switch-right");
      const swiperIndictors = Array.from(
        swiper.querySelectorAll(".swiper-indictor")
      );

      let currentIndex = 0;

      function updateSwiper() {
        swiperItems.forEach((item) => {
          item.style.transform = `translateX(${-currentIndex * 100}%)`;
        });
        swiperIndictors.forEach((indicator, index) => {
          indicator.classList.toggle(
            "swiper-indictor--active",
            index === currentIndex
          );
        });
      }

      function switchTo(index) {
        currentIndex = index;
        updateSwiper();
      }

      swiperSwitchLeft.addEventListener("click", () => {
        switchTo(
          (currentIndex - 1 + swiperItems.length) % swiperItems.length
        );
      });

      swiperSwitchRight.addEventListener("click", () => {
        switchTo((currentIndex + 1) % swiperItems.length);
      });

      swiperIndictors.forEach((indicator, index) => {
        indicator.addEventListener("click", () => {
          switchTo(index);
        });
      });

      updateSwiper();
    });
  </script>

</body>

</html>